version: '3.8'

services:
  # ============================================================================
  # HADOOP HDFS - Distributed Storage
  # ============================================================================
  namenode:
    image: apache/hadoop:3.3.6
    container_name: namenode
    hostname: namenode
    command: ["hdfs", "namenode"]
    user: root
    ports:
      - "9870:9870"  # HDFS Web UI
      - "8020:8020"  # HDFS Port
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    env_file:
      - ./hadoop.env
    volumes:
      - namenode-data:/opt/hadoop/dfs/name
    networks:
      - smartcity-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870"]
      interval: 30s
      timeout: 10s
      retries: 3

  datanode:
    image: apache/hadoop:3.3.6
    container_name: datanode
    hostname: datanode
    command: ["hdfs", "datanode"]
    user: root
    env_file:
      - ./hadoop.env
    volumes:
      - datanode-data:/opt/hadoop/dfs/data
    networks:
      - smartcity-network
    depends_on:
      - namenode

  # ============================================================================
  # KAFKA - Message Queue
  # ============================================================================
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - smartcity-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions.sh --bootstrap-server localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5

  # ============================================================================
  # SPARK - Stream & Batch Processing
  # ============================================================================
  spark-master:
    image: apache/spark:latest
    container_name: spark-master
    hostname: spark-master
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master",
              "--host", "spark-master", "--port", "7077", "--webui-port", "8080"]
    ports:
      - "8888:8080"   # Spark Master Web UI
      - "7077:7077"   # Spark Master Port
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    volumes:
      - ./spark-jobs:/opt/spark-jobs
      - ./data:/opt/data
    networks:
      - smartcity-network
    depends_on:
      - namenode

  spark-worker:
    image: apache/spark:latest
    container_name: spark-worker
    hostname: spark-worker
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker",
              "spark://spark-master:7077"]
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    volumes:
      - ./spark-jobs:/opt/spark-jobs
      - ./data:/opt/data
    networks:
      - smartcity-network
    depends_on:
      - spark-master

  # ============================================================================
  # AIRFLOW - Workflow Orchestration
  # ============================================================================
  postgres-airflow:
    image: postgres:16
    container_name: postgres-airflow
    hostname: postgres-airflow
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres-airflow-data:/var/lib/postgresql/data
    networks:
      - smartcity-network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5

  airflow-init:
    image: apache/airflow:2.8.1
    container_name: airflow-init
    user: root
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - _PIP_ADDITIONAL_REQUIREMENTS=apache-airflow-providers-apache-spark==4.1.3
    entrypoint: /bin/bash
    command: 
      - -c
      - |
        airflow db migrate
        airflow users create \
          --username admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com \
          --password admin || true
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    networks:
      - smartcity-network

  airflow-webserver:
    image: apache/airflow:2.8.1
    container_name: airflow-webserver
    hostname: airflow-webserver
    user: root
    depends_on:
      postgres-airflow:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8082:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - _PIP_ADDITIONAL_REQUIREMENTS=apache-airflow-providers-apache-spark==4.1.3
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: webserver
    networks:
      - smartcity-network
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    image: apache/airflow:2.8.1
    container_name: airflow-scheduler
    hostname: airflow-scheduler
    user: root
    depends_on:
      postgres-airflow:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - _PIP_ADDITIONAL_REQUIREMENTS=apache-airflow-providers-apache-spark==4.1.3
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: scheduler
    networks:
      - smartcity-network

  # ============================================================================
  # POSTGRESQL - Structured Data Storage
  # ============================================================================
  postgres:
    image: postgres:16
    container_name: postgres
    hostname: postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=smartcity
      - POSTGRES_PASSWORD=smartcity
      - POSTGRES_DB=smartcity
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - smartcity-network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "smartcity"]
      interval: 5s
      retries: 5

  # ============================================================================
  # REDIS - Real-time Cache
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: redis
    hostname: redis
    ports:
      - "6380:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    networks:
      - smartcity-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # ============================================================================
  # GRAFANA - Visualization
  # ============================================================================
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    hostname: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - postgres
      - prometheus
    networks:
      - smartcity-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ============================================================================
  # PROMETHEUS - Metrics Collection
  # ============================================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - smartcity-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ============================================================================
  # ADMINER - Database Management UI
  # ============================================================================
  adminer:
    image: adminer:latest
    container_name: adminer
    hostname: adminer
    ports:
      - "8083:8080"
    environment:
      - ADMINER_DEFAULT_SERVER=postgres
    depends_on:
      - postgres
    networks:
      - smartcity-network

volumes:
  kafka-data:
  postgres-data:
  postgres-airflow-data:
  redis-data:
  grafana-data:
  prometheus-data:
  namenode-data:
  datanode-data:

networks:
  smartcity-network:
    driver: bridge